{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF2lN7b3KxIM"
   },
   "source": [
    "# Neural Collaborative Filtering\n",
    "1. [논문](https://arxiv.org/pdf/1708.05031.pdf)\n",
    "2. Keras로 작성된 [저자 코드](https://github.com/hexiangnan/neural_collaborative_filtering)\n",
    "3. 논문은 0과 1로 user-item interaction으로 matrix을 나타내고 학습했으나, 이번 실습에서는 rating을 직접 예측하고, loss를 구해보는 것을 진행한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwo_-gxkMHvu"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9BUxy0TqJpIZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd5EcJo-MNYF"
   },
   "source": [
    "## Load Dataset\n",
    "- KMRD 데이터셋 활용\n",
    "- google colab의 경우 data path 다시 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_ddZzgIiMMZK"
   },
   "outputs": [],
   "source": [
    "data_path = './kmrd-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5MzgHnp4JpIg"
   },
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "  df = pd.read_csv(os.path.join(data_path,'rates.csv'))\n",
    "  train_df, val_df = train_test_split(df, test_size=0.2, random_state=1234, shuffle=True)\n",
    "  return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VZ8oc1G-NYsO"
   },
   "outputs": [],
   "source": [
    "# 학습할 영화 데이터 분석\n",
    "train_df, val_df = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DsohSsCHNeXx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112568, 4)\n",
      "         user  movie  rate        time\n",
      "137023  48423  10764    10  1212241560\n",
      "92868   17307  10170    10  1122185220\n",
      "94390   18180  10048    10  1573403460\n",
      "22289    1498  10001     9  1432684500\n",
      "80155   12541  10022    10  1370458140\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e8qwa_0RNf_z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28142, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ut8hvxxRJpIg"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0bc3455d055b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'col'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'row'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(12,7))\n",
    "ax = ax.ravel()\n",
    "\n",
    "train_df['rate'].hist(ax=ax[0])\n",
    "val_df['rate'].hist(ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ochDMXb5JpIi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    112568.000000\n",
       "mean          8.948369\n",
       "std           2.114602\n",
       "min           1.000000\n",
       "25%           9.000000\n",
       "50%          10.000000\n",
       "75%          10.000000\n",
       "max          10.000000\n",
       "Name: rate, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7Py8f2EXJzv"
   },
   "source": [
    "## Load movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IkPeoquPXNvp"
   },
   "outputs": [],
   "source": [
    "# Load all related dataframe\n",
    "movies_df = pd.read_csv(os.path.join(data_path, 'movies.txt'), sep='\\t', encoding='utf-8')\n",
    "movies_df = movies_df.set_index('movie')\n",
    "\n",
    "castings_df = pd.read_csv(os.path.join(data_path, 'castings.csv'), encoding='utf-8')\n",
    "countries_df = pd.read_csv(os.path.join(data_path, 'countries.csv'), encoding='utf-8')\n",
    "genres_df = pd.read_csv(os.path.join(data_path, 'genres.csv'), encoding='utf-8')\n",
    "\n",
    "# Get genre information\n",
    "genres = [(list(set(x['movie'].values))[0], '/'.join(x['genre'].values)) for index, x in genres_df.groupby('movie')]\n",
    "combined_genres_df = pd.DataFrame(data=genres, columns=['movie', 'genres'])\n",
    "combined_genres_df = combined_genres_df.set_index('movie')\n",
    "\n",
    "# Get castings information\n",
    "castings = [(list(set(x['movie'].values))[0], x['people'].values) for index, x in castings_df.groupby('movie')]\n",
    "combined_castings_df = pd.DataFrame(data=castings, columns=['movie','people'])\n",
    "combined_castings_df = combined_castings_df.set_index('movie')\n",
    "\n",
    "# Get countries for movie information\n",
    "countries = [(list(set(x['movie'].values))[0], ','.join(x['country'].values)) for index, x in countries_df.groupby('movie')]\n",
    "combined_countries_df = pd.DataFrame(data=countries, columns=['movie', 'country'])\n",
    "combined_countries_df = combined_countries_df.set_index('movie')\n",
    "\n",
    "movies_df = pd.concat([movies_df, combined_genres_df, combined_castings_df, combined_countries_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Z6yE06GxYV3W"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_eng</th>\n",
       "      <th>year</th>\n",
       "      <th>grade</th>\n",
       "      <th>genres</th>\n",
       "      <th>people</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>시네마 천국</td>\n",
       "      <td>Cinema Paradiso , 1988</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>전체 관람가</td>\n",
       "      <td>드라마/멜로/로맨스</td>\n",
       "      <td>[4374, 178, 3241, 47952, 47953, 19538, 18991, ...</td>\n",
       "      <td>이탈리아,프랑스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>빽 투 더 퓨쳐</td>\n",
       "      <td>Back To The Future , 1985</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12세 관람가</td>\n",
       "      <td>SF/코미디</td>\n",
       "      <td>[1076, 4603, 917, 8637, 5104, 9986, 7470, 9987]</td>\n",
       "      <td>미국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>빽 투 더 퓨쳐 2</td>\n",
       "      <td>Back To The Future Part 2 , 1989</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12세 관람가</td>\n",
       "      <td>SF/코미디</td>\n",
       "      <td>[1076, 4603, 917, 5104, 391, 5106, 5105, 5107,...</td>\n",
       "      <td>미국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>빽 투 더 퓨쳐 3</td>\n",
       "      <td>Back To The Future Part III , 1990</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>전체 관람가</td>\n",
       "      <td>서부/SF/판타지/코미디</td>\n",
       "      <td>[1076, 4603, 1031, 5104, 10001, 5984, 10002, 1...</td>\n",
       "      <td>미국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>스타워즈 에피소드 4 - 새로운 희망</td>\n",
       "      <td>Star Wars , 1977</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>판타지/모험/SF/액션</td>\n",
       "      <td>[1007, 535, 215, 1236, 35]</td>\n",
       "      <td>미국</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title                           title_eng    year  \\\n",
       "movie                                                                     \n",
       "10001                시네마 천국              Cinema Paradiso , 1988  2013.0   \n",
       "10002              빽 투 더 퓨쳐           Back To The Future , 1985  2015.0   \n",
       "10003            빽 투 더 퓨쳐 2    Back To The Future Part 2 , 1989  2015.0   \n",
       "10004            빽 투 더 퓨쳐 3  Back To The Future Part III , 1990  1990.0   \n",
       "10005  스타워즈 에피소드 4 - 새로운 희망                    Star Wars , 1977  1997.0   \n",
       "\n",
       "         grade         genres  \\\n",
       "movie                           \n",
       "10001   전체 관람가     드라마/멜로/로맨스   \n",
       "10002  12세 관람가         SF/코미디   \n",
       "10003  12세 관람가         SF/코미디   \n",
       "10004   전체 관람가  서부/SF/판타지/코미디   \n",
       "10005       PG   판타지/모험/SF/액션   \n",
       "\n",
       "                                                  people   country  \n",
       "movie                                                               \n",
       "10001  [4374, 178, 3241, 47952, 47953, 19538, 18991, ...  이탈리아,프랑스  \n",
       "10002    [1076, 4603, 917, 8637, 5104, 9986, 7470, 9987]        미국  \n",
       "10003  [1076, 4603, 917, 5104, 391, 5106, 5105, 5107,...        미국  \n",
       "10004  [1076, 4603, 1031, 5104, 10001, 5984, 10002, 1...        미국  \n",
       "10005                         [1007, 535, 215, 1236, 35]        미국  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkIRJboJq-8j"
   },
   "source": [
    "- 논문:  user latent vector + item latent vector\n",
    "- 새롭게 생각할 수 있는 방법: user latent vector + item latent vector + etc vector (예시) meta information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cSfHpEHpJpIi"
   },
   "outputs": [],
   "source": [
    "# 영화 데이터의 메타 정보를 확인한다\n",
    "movieName_dict = movies_df.to_dict()['title']\n",
    "genres_dict = movies_df.to_dict()['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie\n",
       "10001                  시네마 천국\n",
       "10002                빽 투 더 퓨쳐\n",
       "10003              빽 투 더 퓨쳐 2\n",
       "10004              빽 투 더 퓨쳐 3\n",
       "10005    스타워즈 에피소드 4 - 새로운 희망\n",
       "                 ...         \n",
       "10995                  공포의 여정\n",
       "10996                  버스틴 루즈\n",
       "10997                   블랙 엔젤\n",
       "10998                  폭주 기관차\n",
       "10999                  프랑켄슈타인\n",
       "Name: title, Length: 999, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IvnmEfzMJpIj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie\n",
       "10001       드라마/멜로/로맨스\n",
       "10002           SF/코미디\n",
       "10003           SF/코미디\n",
       "10004    서부/SF/판타지/코미디\n",
       "10005     판타지/모험/SF/액션\n",
       "             ...      \n",
       "10995              스릴러\n",
       "10996              코미디\n",
       "10997               공포\n",
       "10998    드라마/액션/모험/스릴러\n",
       "10999        SF/드라마/공포\n",
       "Name: genres, Length: 999, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TygbVbUaJpIl"
   },
   "source": [
    "## Dataset Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76196      True\n",
      "109800    False\n",
      "60479      True\n",
      "71460      True\n",
      "73864      True\n",
      "          ...  \n",
      "64944      True\n",
      "20618      True\n",
      "118034     True\n",
      "69366      True\n",
      "117770    False\n",
      "Length: 28142, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "train_df, val_temp_df = read_data(data_path)\n",
    "unique_users = train_df.user.unique()\n",
    "unique_movies = train_df.movie.unique()\n",
    "print(val_temp_df.user.isin(unique_users) & val_temp_df.movie.isin(unique_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E3bh5SEJJpIl"
   },
   "outputs": [],
   "source": [
    "class DatasetLoader:\n",
    "    def __init__(self, data_path):\n",
    "        #trainset, test set 분류!\n",
    "        self.train_df, val_temp_df = read_data(data_path)\n",
    "\n",
    "        self.min_rating = min(self.train_df.rate)\n",
    "        self.max_rating = self.train_df.rate.max()\n",
    "\n",
    "        self.unique_users = self.train_df.user.unique()\n",
    "        self.num_users = len(self.unique_users)\n",
    "        # 각 user 별 idx를 매김\n",
    "        self.user_to_index = {original: idx for idx, original in enumerate(self.unique_users)}\n",
    "        # 0 1 0 0 0 ... 0\n",
    "\n",
    "        self.unique_movies = self.train_df.movie.unique()\n",
    "        self.num_movies = len(self.unique_movies)\n",
    "        # 각 영화 별 idx를 매김\n",
    "        self.movie_to_index = {original: idx for idx, original in enumerate(self.unique_movies)}\n",
    "        # Bit연산자인데 Boolean 연산자로 이용 (&)\n",
    "        # train_set에 있는 user와 movie 들만 골라서 val_df 만듬\n",
    "        self.val_df = val_temp_df[val_temp_df.user.isin(self.unique_users) & val_temp_df.movie.isin(self.unique_movies)]\n",
    "\n",
    "    def generate_trainset(self):\n",
    "        # user 0, 0, 0, 1,2, 3,3, -> movie: 0,0,0,0,0,0,\n",
    "        X_train = pd.DataFrame({'user': self.train_df.user.map(self.user_to_index),\n",
    "                     'movie': self.train_df.movie.map(self.movie_to_index)})\n",
    "        y_train = self.train_df['rate'].astype(np.float32)\n",
    "\n",
    "        return X_train, y_train\n",
    "\n",
    "    def generate_valset(self):\n",
    "        X_val = pd.DataFrame({'user': self.val_df.user.map(self.user_to_index),\n",
    "                              'movie': self.val_df.movie.map(self.movie_to_index)})\n",
    "        y_val = self.val_df['rate'].astype(np.float32)\n",
    "        return X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep1DLtpHJpIm"
   },
   "source": [
    "## Model Structure\n",
    "- 논문에서 제시한 모델 구조를 그대로 구현하고 영화 데이터로 실습해본다. \n",
    "- User Vector는 전체 영화 데이터에서 영화를 평가한 userid를 onehot vector로 나타낸 형태\n",
    "- Item Vector는 전체 영화 데이터에 등장하는 영화의 id를 onehot vector로 나타낸 형태\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1QAZm2wQJpIm"
   },
   "outputs": [],
   "source": [
    "class FeedForwardEmbedNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users, n_movies, hidden, dropouts, n_factors, embedding_dropout):\n",
    "        super().__init__()\n",
    "        # num_embeddings : 임베딩을 할 단어들의 개수. 다시 말해 단어 집합의 크기입니다.\n",
    "        # embedding_dim : 임베딩 할 벡터의 차원입니다. 사용자가 정해주는 하이퍼파라미터입니다.\n",
    "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
    "        self.movie_emb = nn.Embedding(n_movies, n_factors)\n",
    "        # dropout\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden_layers = nn.Sequential(*list(self.generate_layers(n_factors*2, hidden, dropouts)))\n",
    "        self.fc = nn.Linear(hidden[-1], 1)\n",
    "##embeding 하고 fc까지 만듬\n",
    "    def generate_layers(self, n_factors, hidden, dropouts):\n",
    "        #내부점검 코드 False면 에러 \n",
    "        assert len(dropouts) == len(hidden)\n",
    "\n",
    "        idx = 0\n",
    "        while idx < len(hidden):\n",
    "            if idx == 0:\n",
    "                yield nn.Linear(n_factors, hidden[idx])\n",
    "            else:\n",
    "                yield nn.Linear(hidden[idx-1], hidden[idx])\n",
    "            yield nn.ReLU()\n",
    "            yield nn.Dropout(dropouts[idx])\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "    def forward(self, users, movies, min_rating=0.5, max_rating=5):\n",
    "        concat_features = torch.cat([self.user_emb(users), self.movie_emb(movies)], dim=1)\n",
    "        x = F.relu(self.hidden_layers(concat_features))\n",
    "        # 0과 1사이의 숫자로 나타낸다\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        # rating으로 변환한다\n",
    "        out = (out * (max_rating - min_rating)) + min_rating\n",
    "\n",
    "        return out\n",
    "\n",
    "    def predict(self, users, movies):\n",
    "        # return the score\n",
    "        output_scores = self.forward(users, movies)\n",
    "        return output_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bmy6566FJpIn"
   },
   "outputs": [],
   "source": [
    "class BatchIterator:\n",
    "\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "\n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k * bs:(k + 1) * bs], self.y[k * bs:(k + 1) * bs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qbiX6uwuJpIn"
   },
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for x_batch, y_batch in BatchIterator(X, y, bs, shuffle):\n",
    "        x_batch = torch.LongTensor(x_batch)\n",
    "        y_batch = torch.FloatTensor(y_batch)\n",
    "        yield x_batch, y_batch.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R6I8wWjJpIn"
   },
   "source": [
    "## Train model\n",
    "데이터셋과 모델 학습에 필요한 configuration을 입력하고, 학습을 하는 함수를 만든다\n",
    "configuration을 바꾸면서 모델의 성능을 측정해볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#   \"num_factors\": 16,\n",
    "#   \"hidden_layers\": [64, 32, 16],\n",
    "#   \"embedding_dropout\": 0.05,\n",
    "#   \"dropouts\": [0.3, 0.3, 0.3],\n",
    "#   \"learning_rate\": 1e-3,\n",
    "#   \"weight_decay\": 1e-5,\n",
    "#   \"batch_size\": 8,\n",
    "#   \"num_epochs\": 3,\n",
    "#   \"total_patience\": 30,\n",
    "#   \"save_path\": \"params.data\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6stv_nRnJpIo"
   },
   "outputs": [],
   "source": [
    "# ds = dataset, Dataloader class\n",
    "def model_train(ds, config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    X_train, y_train = ds.generate_trainset()\n",
    "    X_valid, y_valid = ds.generate_valset()\n",
    "    print(f'TrainSet Info: {ds.num_users} users, {ds.num_movies} movies')\n",
    "#Embeding 하는 정의한 function\n",
    "    model = FeedForwardEmbedNN(\n",
    "        n_users=ds.num_users, n_movies=ds.num_movies,\n",
    "        n_factors=config['num_factors'], hidden=config['hidden_layers'],\n",
    "        embedding_dropout=config['embedding_dropout'], dropouts=config['dropouts']\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    batch_size = config['batch_size']\n",
    "    num_epochs = config['num_epochs']\n",
    "    max_patience = config['total_patience']\n",
    "    num_patience = 0\n",
    "    best_loss = np.inf\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    criterion.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    result = dict()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        training_loss = 0.0\n",
    "        for batch in batches(X_train, y_train, shuffle=True, bs=batch_size):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # with torch.no_grad() 와 동일한 syntax 입니다\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(x_batch[:, 0], x_batch[:, 1], ds.min_rating, ds.max_rating)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "        result['train'] = training_loss / len(X_train)\n",
    "\n",
    "        # Apply Early Stopping criteria and save best model params\n",
    "        val_outputs = model(torch.LongTensor(X_valid.user.values).to(device),\n",
    "                            torch.LongTensor(X_valid.movie.values).to(device), ds.min_rating, ds.max_rating)\n",
    "        val_loss = criterion(val_outputs.to(device), torch.FloatTensor(y_valid.values).view(-1, 1).to(device))\n",
    "        result['val'] = float((val_loss / len(X_valid)).data)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            print('Save new model on epoch: %d' % (epoch + 1))\n",
    "            best_loss = val_loss\n",
    "            result['best_loss'] = val_loss\n",
    "            torch.save(model.state_dict(), config['save_path'])\n",
    "            num_patience = 0\n",
    "        else:\n",
    "            num_patience += 1\n",
    "\n",
    "        print(f'[epoch: {epoch+1}] train: {result[\"train\"]} - val: {result[\"val\"]}')\n",
    "\n",
    "        if num_patience >= max_patience:\n",
    "            print(f\"Early Stopped after epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fawHamk_JpIo"
   },
   "outputs": [],
   "source": [
    "def model_valid(user_id_list, movie_id_list, data_path):\n",
    "    dataset = DatasetLoader(data_path)\n",
    "    processed_test_input_df = pd.DataFrame({\n",
    "        'user_id': [dataset.user_to_index[x] for x in user_id_list],\n",
    "        'movie_id': [dataset.movie_to_index[x] for x in movie_id_list]\n",
    "    })\n",
    "\n",
    "    # 학습한 모델 load하기 \n",
    "    my_model = FeedForwardEmbedNN(dataset.num_users, dataset.num_movies,\n",
    "                       config['hidden_layers'], config['dropouts'], config['num_factors'], config['embedding_dropout'])\n",
    "    my_model.load_state_dict(torch.load('params.data'))\n",
    "    prediction_outputs = my_model.predict(users=torch.LongTensor(processed_test_input_df.user_id.values),\n",
    "                     movies=torch.LongTensor(processed_test_input_df.movie_id.values))\n",
    "\n",
    "    return prediction_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "liavZI4zJpIp"
   },
   "outputs": [],
   "source": [
    "dataset = DatasetLoader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1xEzqD2cJpIp"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"num_factors\": 16,\n",
    "  \"hidden_layers\": [64, 32, 16],\n",
    "  \"embedding_dropout\": 0.05,\n",
    "  \"dropouts\": [0.3, 0.3, 0.3],\n",
    "  \"learning_rate\": 1e-3,\n",
    "  \"weight_decay\": 1e-5,\n",
    "  \"batch_size\": 8,\n",
    "  \"num_epochs\": 10,\n",
    "  \"total_patience\": 30,\n",
    "  \"save_path\": \"params.data\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9SFyhQr-JpIp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainSet Info: 44453 users, 597 movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [01:32<13:50, 92.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save new model on epoch: 1\n",
      "[epoch: 1] train: 4.294581674571511 - val: 3.853483200073242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [03:01<12:11, 91.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save new model on epoch: 2\n",
      "[epoch: 2] train: 3.7398429559590722 - val: 3.5757853984832764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [04:30<10:34, 90.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save new model on epoch: 3\n",
      "[epoch: 3] train: 3.3241739442390843 - val: 3.5476973056793213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [05:58<08:59, 89.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4] train: 3.078868815795971 - val: 3.607912063598633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [07:28<07:28, 89.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save new model on epoch: 5\n",
      "[epoch: 5] train: 2.978546805940444 - val: 3.5405774116516113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [08:56<05:57, 89.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save new model on epoch: 6\n",
      "[epoch: 6] train: 2.92381301109163 - val: 3.540335178375244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [10:24<04:26, 89.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save new model on epoch: 7\n",
      "[epoch: 7] train: 2.8730494283832124 - val: 3.526031255722046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [11:52<02:57, 88.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 8] train: 2.835697396790537 - val: 3.5578243732452393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [13:21<01:28, 88.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 9] train: 2.7497691948461203 - val: 3.6668848991394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [14:52<00:00, 89.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 10] train: 2.7274196418920513 - val: 3.681518316268921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 2.7274196418920513,\n",
       " 'val': 3.681518316268921,\n",
       " 'best_loss': tensor(71423.2891, grad_fn=<MseLossBackward>)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train(dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "66PToOALWUZB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76196</th>\n",
       "      <td>11242</td>\n",
       "      <td>10253</td>\n",
       "      <td>10</td>\n",
       "      <td>1437788760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76191</th>\n",
       "      <td>11242</td>\n",
       "      <td>10020</td>\n",
       "      <td>10</td>\n",
       "      <td>1435493160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76197</th>\n",
       "      <td>11242</td>\n",
       "      <td>10479</td>\n",
       "      <td>10</td>\n",
       "      <td>1437611280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  movie  rate        time\n",
       "76196  11242  10253    10  1437788760\n",
       "76191  11242  10020    10  1435493160\n",
       "76197  11242  10479    10  1437611280"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[val_df['user'] == 11242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ukvOFg52JpIq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>pred_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11242</td>\n",
       "      <td>10102</td>\n",
       "      <td>4.945162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11242</td>\n",
       "      <td>10253</td>\n",
       "      <td>4.669635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11242</td>\n",
       "      <td>10007</td>\n",
       "      <td>4.627274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  pred_ratings\n",
       "1   11242    10102      4.945162\n",
       "0   11242    10253      4.669635\n",
       "2   11242    10007      4.627274"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id_list = [10253, 10102, 10007]\n",
    "user_id = 11242\n",
    "user_id_list = [user_id] * len(movie_id_list)\n",
    "pred_results = [float(x) for x in model_valid(user_id_list, movie_id_list, data_path)]\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'userId': user_id_list,\n",
    "    'movieId': movie_id_list,\n",
    "    # 'movieName': [movieName_dict[x] for x in movie_id_list],\n",
    "    # 'genres': [genres_dict[x] for x in movie_id_list],\n",
    "    'pred_ratings': pred_results\n",
    "})\n",
    "\n",
    "result_df.sort_values(by='pred_ratings', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01-딥러닝과 추천알고리즘-03-Neural Collaborative Filtering 실습.ipynb",
   "provenance": [
    {
     "file_id": "1nAG9mn7f8YFOELV2UsbkEruQHOCXngCs",
     "timestamp": 1609776703964
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
